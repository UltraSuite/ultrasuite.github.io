{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"UltraSuite A repository of ultrasound and acoustic data from child speech therapy sessions UltraSuite is a repository of ultrasound and acoustic data from child speech therapy sessions. The current release includes three data collections, one from typically developing children and two from children with speech sound disorders. It also includes a set of annotations, some manual and some automatically produced, and tools to process, transform and visualise the data. Read the paper here! Data There are three datasets available in the repository: Ultrax Typically Developing - UXTD Ultrax Speech Sound Disorders - UXSSD UltraPhonix (disordered speech) - UPX Download links will be made available soon. Code Ultrasuite Tools - Python library to process raw ultrasound data. Ultrasuite Kaldi (soon) - Recipes and other code to use UltraSuite data with the Kaldi Speech Recognition Toolkit . Frequently Asked Questions See the FAQ for a number of additional details regaring this repository. Contributing We welcome user contribution to UltraSuite! We are hoping to keep UltraSuite in active development with help from the community. All contributions will be given proper credits! There are various ways to participate: Contributing with data The current release of UltraSuite has three datasets of ultrasound and audio from Child speech, but we hope to include additional datasets from other modalities (e.g. MRI) and age groups (e.g. Adults). If you'd like share data that you collected through UltraSuite, please get in touch with any member of the Ultrax Speech project . Note that even though data is available through UltraSuite, we encourage users to cite the original authors. Contributing with code To contribute with code or to help improve this documentations, please submit your changes with Pull Requests. Reporting issues To report any issues, you can use GitHub's Issue Tracker or you can contact any member of the Ultrax Speech project . Please submit any issues related to code in their respective repositories using Github's Issue Tracker. For issues found in the data, please contact us directly. License Datasets from UltraSuite are distributed under Attribution-NonCommercial 4.0 Generic (CC BY-NC 4.0). Code is available under the Apache License v.2. Citation If using data or code from UltraSuite, please provide appropriate web links and cite the following paper: Eshky, A., Ribeiro, M. S., Cleland, J., Richmond, K., Roxburgh, Z., Scobbie, J., & Wrench, A. (2018) Ultrasuite: A repository of ultrasound and acoustic data from child speech therapy sessions . Proceedings of INTERSPEECH. Hyderabad, India. [ pdf ] [ bibtex ]","title":"Home"},{"location":"#ultrasuite","text":"","title":"UltraSuite"},{"location":"#a-repository-of-ultrasound-and-acoustic-data-from-child-speech-therapy-sessions","text":"UltraSuite is a repository of ultrasound and acoustic data from child speech therapy sessions. The current release includes three data collections, one from typically developing children and two from children with speech sound disorders. It also includes a set of annotations, some manual and some automatically produced, and tools to process, transform and visualise the data. Read the paper here!","title":"A repository of ultrasound and acoustic data from child speech therapy sessions"},{"location":"#data","text":"There are three datasets available in the repository: Ultrax Typically Developing - UXTD Ultrax Speech Sound Disorders - UXSSD UltraPhonix (disordered speech) - UPX Download links will be made available soon.","title":"Data"},{"location":"#code","text":"Ultrasuite Tools - Python library to process raw ultrasound data. Ultrasuite Kaldi (soon) - Recipes and other code to use UltraSuite data with the Kaldi Speech Recognition Toolkit .","title":"Code"},{"location":"#frequently-asked-questions","text":"See the FAQ for a number of additional details regaring this repository.","title":"Frequently Asked Questions"},{"location":"#contributing","text":"We welcome user contribution to UltraSuite! We are hoping to keep UltraSuite in active development with help from the community. All contributions will be given proper credits! There are various ways to participate:","title":"Contributing"},{"location":"#contributing-with-data","text":"The current release of UltraSuite has three datasets of ultrasound and audio from Child speech, but we hope to include additional datasets from other modalities (e.g. MRI) and age groups (e.g. Adults). If you'd like share data that you collected through UltraSuite, please get in touch with any member of the Ultrax Speech project . Note that even though data is available through UltraSuite, we encourage users to cite the original authors.","title":"Contributing with data"},{"location":"#contributing-with-code","text":"To contribute with code or to help improve this documentations, please submit your changes with Pull Requests.","title":"Contributing with code"},{"location":"#reporting-issues","text":"To report any issues, you can use GitHub's Issue Tracker or you can contact any member of the Ultrax Speech project . Please submit any issues related to code in their respective repositories using Github's Issue Tracker. For issues found in the data, please contact us directly.","title":"Reporting issues"},{"location":"#license","text":"Datasets from UltraSuite are distributed under Attribution-NonCommercial 4.0 Generic (CC BY-NC 4.0). Code is available under the Apache License v.2.","title":"License"},{"location":"#citation","text":"If using data or code from UltraSuite, please provide appropriate web links and cite the following paper: Eshky, A., Ribeiro, M. S., Cleland, J., Richmond, K., Roxburgh, Z., Scobbie, J., & Wrench, A. (2018) Ultrasuite: A repository of ultrasound and acoustic data from child speech therapy sessions . Proceedings of INTERSPEECH. Hyderabad, India. [ pdf ] [ bibtex ]","title":"Citation"},{"location":"faq/","text":"Frequently Asked Questions Why is there a difference in the numbers reported here and those in the paper? Why is there silence in some waveforms? I found an issue in one or more utterances. How can I report it? How can I interpret ultrasound parameters? How can I cite UltraSuite? Why is there a difference in the numbers reported here and those in the paper? Some of the numbers describing the repository in the paper, such as number of utterances or number of speech hours, were estimated at the time of the submission. We are actively working on improving UltraSuite, which means these number might change. For example, estimates for speech hours (child or therapist speech and silence) may change due to different speaker labelling methods or the removal of identifiable information. The number of utterances may change if we find unusable utterances (poor recording or corrupted data). To keep track of these changes, please be aware of version numbers in the datasets and their respective labels. Why is there silence in some waveforms? Some utterances contain regions of artificial silence. These correspond to regions originally containing identifiable information (such as children's names) and speech from additional speakers (such as parent speech). To remove such data, we have replaced them with silence in the waveform. I found an issue in one or more utterances. How can I report it? Please see Contributing . How can I interpret ultrasound parameters? TODO How can I cite UltraSuite? For the current release of UltraSuite, if using data or code, please provide appropriate web links and cite the following paper: Eshky, A., Ribeiro, M. S., Cleland, J., Richmond, K., Roxburgh, Z., Scobbie, J., & Wrench, A. (2018) Ultrasuite: A repository of ultrasound and acoustic data from child speech therapy sessions . Proceedings of INTERSPEECH. Hyderabad, India.","title":"Frequently Asked Questions"},{"location":"faq/#frequently-asked-questions","text":"Why is there a difference in the numbers reported here and those in the paper? Why is there silence in some waveforms? I found an issue in one or more utterances. How can I report it? How can I interpret ultrasound parameters? How can I cite UltraSuite?","title":"Frequently Asked Questions"},{"location":"faq/#why-is-there-a-difference-in-the-numbers-reported-here-and-those-in-the-paper","text":"Some of the numbers describing the repository in the paper, such as number of utterances or number of speech hours, were estimated at the time of the submission. We are actively working on improving UltraSuite, which means these number might change. For example, estimates for speech hours (child or therapist speech and silence) may change due to different speaker labelling methods or the removal of identifiable information. The number of utterances may change if we find unusable utterances (poor recording or corrupted data). To keep track of these changes, please be aware of version numbers in the datasets and their respective labels.","title":"Why is there a difference in the numbers reported here and those in the paper?"},{"location":"faq/#why-is-there-silence-in-some-waveforms","text":"Some utterances contain regions of artificial silence. These correspond to regions originally containing identifiable information (such as children's names) and speech from additional speakers (such as parent speech). To remove such data, we have replaced them with silence in the waveform.","title":"Why is there silence in some waveforms?"},{"location":"faq/#i-found-an-issue-in-one-or-more-utterances-how-can-i-report-it","text":"Please see Contributing .","title":"I found an issue in one or more utterances. How can I report it?"},{"location":"faq/#how-can-i-interpret-ultrasound-parameters","text":"TODO","title":"How can I interpret ultrasound parameters?"},{"location":"faq/#how-can-i-cite-ultrasuite","text":"For the current release of UltraSuite, if using data or code, please provide appropriate web links and cite the following paper: Eshky, A., Ribeiro, M. S., Cleland, J., Richmond, K., Roxburgh, Z., Scobbie, J., & Wrench, A. (2018) Ultrasuite: A repository of ultrasound and acoustic data from child speech therapy sessions . Proceedings of INTERSPEECH. Hyderabad, India.","title":"How can I cite UltraSuite?"},{"location":"data/data/","text":"Data Description Prompt Types There are six different prompt types, encoding the task with was requested of the child. Please see section 3.1 of Eshky et al (2018) for further details. Type ID UXTD UXSSD UPX Words A 962 (26) 2708 (291) 3838 (455) Non-words B 607 (27) 495 (59) 560 (60) Sentence C 0 (0) 445 (35) 1020 (128) Articulatory D 2934 (45) 132 (17) 211 (21) Non-speech E 116 (2) 9 (1) 302 (1) Other F 0 (0) 56 (12) 61 (1) Total 4619 (100) 3845 (415) 5992 (682) Speech Hours The following hours of speech and silence are rounded to two decimal places and are estimated using the speaker labels that accompany each dataset. UXTD UXSSD UPX Child speech 2.24 (28.39%) 3.66 (34.45%) 7.27 (38.70%) SLT speech 1.24 (15.74%) 1.81 (16.99%) 1.92 (10.23%) Total speech 3.47 (44.12%) 5.47 (51.43%) 9.19 (48.93%) Initial silence 1.41 (17.96%) 0.91 (8.55%) 0.78 (4.17%) Medial silence 1.99 (25.30%) 3.48 (32.69%) 7.11 (37.83%) Final silence 0.99 (12.61%) 0.78 (7.32%) 1.70 (9.07%) Total silence 4.40 (55.88%) 5.16 (48.57%) 9.59 (51.07%) Total Audio 7.87 10.63 18.78","title":"Data Description"},{"location":"data/data/#data-description","text":"","title":"Data Description"},{"location":"data/data/#prompt-types","text":"There are six different prompt types, encoding the task with was requested of the child. Please see section 3.1 of Eshky et al (2018) for further details. Type ID UXTD UXSSD UPX Words A 962 (26) 2708 (291) 3838 (455) Non-words B 607 (27) 495 (59) 560 (60) Sentence C 0 (0) 445 (35) 1020 (128) Articulatory D 2934 (45) 132 (17) 211 (21) Non-speech E 116 (2) 9 (1) 302 (1) Other F 0 (0) 56 (12) 61 (1) Total 4619 (100) 3845 (415) 5992 (682)","title":"Prompt Types"},{"location":"data/data/#speech-hours","text":"The following hours of speech and silence are rounded to two decimal places and are estimated using the speaker labels that accompany each dataset. UXTD UXSSD UPX Child speech 2.24 (28.39%) 3.66 (34.45%) 7.27 (38.70%) SLT speech 1.24 (15.74%) 1.81 (16.99%) 1.92 (10.23%) Total speech 3.47 (44.12%) 5.47 (51.43%) 9.19 (48.93%) Initial silence 1.41 (17.96%) 0.91 (8.55%) 0.78 (4.17%) Medial silence 1.99 (25.30%) 3.48 (32.69%) 7.11 (37.83%) Final silence 0.99 (12.61%) 0.78 (7.32%) 1.70 (9.07%) Total silence 4.40 (55.88%) 5.16 (48.57%) 9.59 (51.07%) Total Audio 7.87 10.63 18.78","title":"Speech Hours"},{"location":"data/upx/","text":"UPX - UltraPhonix A dataset of ultrasound and audio recordings from children with speech sound disorders Speakers TODO Sessions Session Description Suit Suitability session to determine if child needs speech therapy BL Baseline session before therapy (1-2 sessions) Mid Mid-point session, halfway through therapy Post Post-therapy session, immediately after therapy ended Maint Maintenance session, some time after therapy ended Therapy Therapy sessions Data Types Core data types Data type Description wav speech waveform ult raw ultrasound data param ultrasound parameters txt prompt text with date/time of utterance recording Additional data All labels are provided in Praat's TextGrid format. Data type Description slt-labels manual annotation from SLT, when available. See [2] for details speaker-labels speaker diarization identifying therapist (SLT) and child (CHILD) speech word-labels automatic word-level alignment phone-labels automatic phone-level alignment File IDs Individual recordings are indexed for each session according to their recording times. See the prompt text file for recording date/time. Each file ID also includes a prompt type identifier. See Data for details. Download Download links will be made available soon References [1] Eshky, A., Ribeiro, M. S., Cleland, J., Richmond, K., Roxburgh, Z., Scobbie, J., & Wrench, A. (2018) Ultrasuite: A repository of ultrasound and acoustic data from child speech therapy sessions . Proceedings of INTERSPEECH. Hyderabad, India. [2] Cleland, J., Scobbie, J. M., Heyde, C., Roxburgh, Z., & Wrench, A. A. (2017). Covert contrast and covert errors in persistent velar fronting . Clinical linguistics & phonetics, 31(1), 35-55. [3] Cleland, J., Scobbie, J. M., Roxburgh, Z., Heyde, C., & Wrench, A. A. (Under Revision). Enabling New Articulatory Gestures in Children with Persistent Speech Sound Disorders using Ultrasound Visual Biofeedback . Journal of Speech, Language, and Hearing Research.","title":"Ultraphonix"},{"location":"data/upx/#upx-ultraphonix","text":"","title":"UPX - UltraPhonix"},{"location":"data/upx/#a-dataset-of-ultrasound-and-audio-recordings-from-children-with-speech-sound-disorders","text":"","title":"A dataset of ultrasound and audio recordings from children with speech sound disorders"},{"location":"data/upx/#speakers","text":"TODO","title":"Speakers"},{"location":"data/upx/#sessions","text":"Session Description Suit Suitability session to determine if child needs speech therapy BL Baseline session before therapy (1-2 sessions) Mid Mid-point session, halfway through therapy Post Post-therapy session, immediately after therapy ended Maint Maintenance session, some time after therapy ended Therapy Therapy sessions","title":"Sessions"},{"location":"data/upx/#data-types","text":"Core data types Data type Description wav speech waveform ult raw ultrasound data param ultrasound parameters txt prompt text with date/time of utterance recording Additional data All labels are provided in Praat's TextGrid format. Data type Description slt-labels manual annotation from SLT, when available. See [2] for details speaker-labels speaker diarization identifying therapist (SLT) and child (CHILD) speech word-labels automatic word-level alignment phone-labels automatic phone-level alignment","title":"Data Types"},{"location":"data/upx/#file-ids","text":"Individual recordings are indexed for each session according to their recording times. See the prompt text file for recording date/time. Each file ID also includes a prompt type identifier. See Data for details.","title":"File IDs"},{"location":"data/upx/#download","text":"Download links will be made available soon","title":"Download"},{"location":"data/upx/#references","text":"[1] Eshky, A., Ribeiro, M. S., Cleland, J., Richmond, K., Roxburgh, Z., Scobbie, J., & Wrench, A. (2018) Ultrasuite: A repository of ultrasound and acoustic data from child speech therapy sessions . Proceedings of INTERSPEECH. Hyderabad, India. [2] Cleland, J., Scobbie, J. M., Heyde, C., Roxburgh, Z., & Wrench, A. A. (2017). Covert contrast and covert errors in persistent velar fronting . Clinical linguistics & phonetics, 31(1), 35-55. [3] Cleland, J., Scobbie, J. M., Roxburgh, Z., Heyde, C., & Wrench, A. A. (Under Revision). Enabling New Articulatory Gestures in Children with Persistent Speech Sound Disorders using Ultrasound Visual Biofeedback . Journal of Speech, Language, and Hearing Research.","title":"References"},{"location":"data/uxssd/","text":"UXSSD - Ultrax Speech Sound Disorders A dataset of ultrasound and audio recordings from children with speech sound disorders Speakers The UXSSD dataset contains 8 speakers (2 female and 6 male), aged 5-10 years. The table below give further details for each speaker. Ages were taken in the first Assessment session and are indicated in years (AGE-Y) and months (AGE-M). SPEAKER-ID GENDER AGE-Y AGE-M AGE 01M M 6 0 6.0 02M M 10 1 10.08 03F F 8 7 8.58 04M M 8 11 8.92 05M M 6 5 6.42 06M M 5 11 5.92 07F F 7 6 7.5 08M M 7 7 7.58 Sessions Session Description BL Baseline session before therapy (1-2 sessions) Mid Mid-point session, halfway through therapy Post Post-therapy session, immediately after therapy ended Maint Maintenance session, some time after therapy ended Therapy Therapy sessions Data Types Core data types Data type Description wav speech waveform ult raw ultrasound data param ultrasound parameters txt prompt text with date/time of utterance recording Additional data All labels are provided in Praat's TextGrid format. Data type Description slt-labels manual annotation from SLT, when available. See [2] for details speaker-labels speaker diarization identifying therapist (SLT) and child (CHILD) speech word-labels automatic word-level alignment phone-labels automatic phone-level alignment File IDs Individual recordings are indexed for each session according to their recording times. See the prompt text file for recording date/time. Each file ID also includes a prompt type identifier. See Data for details. Additional Notes Speaker 05M was subjected to two rounds of therapy, with corresponding Assessment sessions. These are identified as *_round2 in the speaker directory. Therapy sessions for this speaker are indexed chronologically. Download Download links will be made available soon References [1] Eshky, A., Ribeiro, M. S., Cleland, J., Richmond, K., Roxburgh, Z., Scobbie, J., & Wrench, A. (2018) Ultrasuite: A repository of ultrasound and acoustic data from child speech therapy sessions . Proceedings of INTERSPEECH. Hyderabad, India. [2] Cleland, J., Scobbie, J. M., & Wrench, A. A. (2015). Using ultrasound visual biofeedback to treat persistent primary speech sound disorders . Clinical linguistics & phonetics, 29(8-10), 575-597.","title":"Ultrax Speech Sound Disorders"},{"location":"data/uxssd/#uxssd-ultrax-speech-sound-disorders","text":"","title":"UXSSD - Ultrax Speech Sound Disorders"},{"location":"data/uxssd/#a-dataset-of-ultrasound-and-audio-recordings-from-children-with-speech-sound-disorders","text":"","title":"A dataset of ultrasound and audio recordings from children with speech sound disorders"},{"location":"data/uxssd/#speakers","text":"The UXSSD dataset contains 8 speakers (2 female and 6 male), aged 5-10 years. The table below give further details for each speaker. Ages were taken in the first Assessment session and are indicated in years (AGE-Y) and months (AGE-M). SPEAKER-ID GENDER AGE-Y AGE-M AGE 01M M 6 0 6.0 02M M 10 1 10.08 03F F 8 7 8.58 04M M 8 11 8.92 05M M 6 5 6.42 06M M 5 11 5.92 07F F 7 6 7.5 08M M 7 7 7.58","title":"Speakers"},{"location":"data/uxssd/#sessions","text":"Session Description BL Baseline session before therapy (1-2 sessions) Mid Mid-point session, halfway through therapy Post Post-therapy session, immediately after therapy ended Maint Maintenance session, some time after therapy ended Therapy Therapy sessions","title":"Sessions"},{"location":"data/uxssd/#data-types","text":"Core data types Data type Description wav speech waveform ult raw ultrasound data param ultrasound parameters txt prompt text with date/time of utterance recording Additional data All labels are provided in Praat's TextGrid format. Data type Description slt-labels manual annotation from SLT, when available. See [2] for details speaker-labels speaker diarization identifying therapist (SLT) and child (CHILD) speech word-labels automatic word-level alignment phone-labels automatic phone-level alignment","title":"Data Types"},{"location":"data/uxssd/#file-ids","text":"Individual recordings are indexed for each session according to their recording times. See the prompt text file for recording date/time. Each file ID also includes a prompt type identifier. See Data for details.","title":"File IDs"},{"location":"data/uxssd/#additional-notes","text":"Speaker 05M was subjected to two rounds of therapy, with corresponding Assessment sessions. These are identified as *_round2 in the speaker directory. Therapy sessions for this speaker are indexed chronologically.","title":"Additional Notes"},{"location":"data/uxssd/#download","text":"Download links will be made available soon","title":"Download"},{"location":"data/uxssd/#references","text":"[1] Eshky, A., Ribeiro, M. S., Cleland, J., Richmond, K., Roxburgh, Z., Scobbie, J., & Wrench, A. (2018) Ultrasuite: A repository of ultrasound and acoustic data from child speech therapy sessions . Proceedings of INTERSPEECH. Hyderabad, India. [2] Cleland, J., Scobbie, J. M., & Wrench, A. A. (2015). Using ultrasound visual biofeedback to treat persistent primary speech sound disorders . Clinical linguistics & phonetics, 29(8-10), 575-597.","title":"References"},{"location":"data/uxtd-spk/","text":"UXTD - Ultrax Typically Developing Children A dataset of ultrasound and audio recordings from typically developing children Speaker list of UltraSuite's UXTD dataset. Speakers SPEAKER-ID GROUP GENDER AGE-Y AGE-M AGE RECORDING DATE SUBSET 01M 1 M 11 10 11.83 13/11/2011 TRAIN 02M 1 M 11 9 11.75 22/12/2011 TRAIN 03F 1 F 10 5 10.42 27/01/2011 TRAIN 04M 1 M 8 9 8.75 27/01/2011 TRAIN 05M 1 M 9 11 9.92 03/02/2012 TRAIN 06F 1 F 9 10 9.83 14/02/2012 TRAIN 07F 1 F 9 4 9.33 14/02/2012 TEST 08M 1 M 8 8 8.67 16/02/2012 TEST 09F 1 F 6 9 6.75 16/02/2012 TRAIN 10F 1 F 11 3 11.25 17/02/2012 TRAIN 11M 1 M 8 1 8.08 09/03/2012 TRAIN 12M 1 M 6 8 6.67 15/03/2012 TEST 13F 1 F 11 7 11.58 21/03/2012 TEST 14M 1 M 12 4 12.33 21/03/2012 TRAIN 15M 1 M 7 11 7.92 21/03/2012 TRAIN 16F 1 F 12 10 12.83 21/03/2012 TRAIN 17M 1 M 10 8 10.67 21/02/2012 DEV 18F 1 F 7 2 7.17 30/03/2012 TRAIN 19M 1 M 12 6 12.5 30/03/2012 TRAIN 20M 1 M 11 1 11.08 02/04/2012 TRAIN 21F 1 F 5 8 5.67 03/04/2012 TRAIN 22M 1 M 12 2 12.17 03/04/2012 DEV 23F 1 F 12 2 12.17 03/04/2012 TRAIN 24F 1 F 8 7 8.58 03/04/2012 TRAIN 25M 1 M 10 0 10 03/04/2012 TRAIN 26F 1 F 7 11 7.92 04/04/2012 TEST 27M 1 M 11 5 11.42 10/04/2012 TRAIN 28F 1 F 7 3 7.25 10/04/2012 TRAIN 29F 1 F 7 11 7.92 13/04/2012 TRAIN 30F 1 F 10 5 10.42 16/04/2012 TEST 31F 2 F 9 6 9.5 27/04/2012 TRAIN 32F 2 F 11 8 11.67 02/05/2012 DEV 33F 2 F 8 8 8.67 04/05/2012 TRAIN 34M 2 M 9 11 9.92 24/05/2012 TRAIN 35M 2 M 7 11 7.92 25/05/2012 TRAIN 36M 2 M 10 7 10.58 30/05/2012 TRAIN 37M 2 M 8 7 8.58 31/05/2012 DEV 38M 2 M 9 6 9.5 01/06/2012 TEST 39F 2 F 10 8 10.67 01/06/2012 TEST 40M 2 M 9 1 9.08 05/06/2012 TRAIN 41F 2 F 7 6 7.5 07/06/2012 TRAIN 42M 2 M 8 11 8.92 08/06/2012 TRAIN 43F 2 F 10 1 10.08 14/06/2012 TRAIN 44F 2 F 7 11 7.92 15/06/2012 TRAIN 45M 2 M 10 5 10.42 15/06/2012 TEST 46F 2 F 6 11 6.92 18/06/2012 TRAIN 47M 2 M 11 8 11.67 25/06/2012 TEST 48F 2 F 10 10 10.83 04/07/2012 TRAIN 49F 2 F 8 9 8.75 03/08/2012 TRAIN 50F 2 F 10 6 10.5 03/10/2012 TRAIN 51M 2 M 7 7 7.58 03/10/2012 TRAIN 52F 2 F 8 3 8.25 05/10/2012 TEST 53F 2 F 6 0 6.0 05/10/2012 TEST 54F 2 F 8 2 8.17 09/10/2012 TRAIN 55M 2 M 7 5 7.42 12/10/2012 TEST 56M 2 M 6 9 6.75 16/10/2012 TRAIN 57F 2 F 7 5 7.42 16/10/2012 DEV 58F 2 F 9 1 9.08 17/10/2012 DEV","title":"UXTD - Ultrax Typically Developing Children"},{"location":"data/uxtd-spk/#uxtd-ultrax-typically-developing-children","text":"","title":"UXTD - Ultrax Typically Developing Children"},{"location":"data/uxtd-spk/#a-dataset-of-ultrasound-and-audio-recordings-from-typically-developing-children","text":"Speaker list of UltraSuite's UXTD dataset.","title":"A dataset of ultrasound and audio recordings from typically developing children"},{"location":"data/uxtd-spk/#speakers","text":"SPEAKER-ID GROUP GENDER AGE-Y AGE-M AGE RECORDING DATE SUBSET 01M 1 M 11 10 11.83 13/11/2011 TRAIN 02M 1 M 11 9 11.75 22/12/2011 TRAIN 03F 1 F 10 5 10.42 27/01/2011 TRAIN 04M 1 M 8 9 8.75 27/01/2011 TRAIN 05M 1 M 9 11 9.92 03/02/2012 TRAIN 06F 1 F 9 10 9.83 14/02/2012 TRAIN 07F 1 F 9 4 9.33 14/02/2012 TEST 08M 1 M 8 8 8.67 16/02/2012 TEST 09F 1 F 6 9 6.75 16/02/2012 TRAIN 10F 1 F 11 3 11.25 17/02/2012 TRAIN 11M 1 M 8 1 8.08 09/03/2012 TRAIN 12M 1 M 6 8 6.67 15/03/2012 TEST 13F 1 F 11 7 11.58 21/03/2012 TEST 14M 1 M 12 4 12.33 21/03/2012 TRAIN 15M 1 M 7 11 7.92 21/03/2012 TRAIN 16F 1 F 12 10 12.83 21/03/2012 TRAIN 17M 1 M 10 8 10.67 21/02/2012 DEV 18F 1 F 7 2 7.17 30/03/2012 TRAIN 19M 1 M 12 6 12.5 30/03/2012 TRAIN 20M 1 M 11 1 11.08 02/04/2012 TRAIN 21F 1 F 5 8 5.67 03/04/2012 TRAIN 22M 1 M 12 2 12.17 03/04/2012 DEV 23F 1 F 12 2 12.17 03/04/2012 TRAIN 24F 1 F 8 7 8.58 03/04/2012 TRAIN 25M 1 M 10 0 10 03/04/2012 TRAIN 26F 1 F 7 11 7.92 04/04/2012 TEST 27M 1 M 11 5 11.42 10/04/2012 TRAIN 28F 1 F 7 3 7.25 10/04/2012 TRAIN 29F 1 F 7 11 7.92 13/04/2012 TRAIN 30F 1 F 10 5 10.42 16/04/2012 TEST 31F 2 F 9 6 9.5 27/04/2012 TRAIN 32F 2 F 11 8 11.67 02/05/2012 DEV 33F 2 F 8 8 8.67 04/05/2012 TRAIN 34M 2 M 9 11 9.92 24/05/2012 TRAIN 35M 2 M 7 11 7.92 25/05/2012 TRAIN 36M 2 M 10 7 10.58 30/05/2012 TRAIN 37M 2 M 8 7 8.58 31/05/2012 DEV 38M 2 M 9 6 9.5 01/06/2012 TEST 39F 2 F 10 8 10.67 01/06/2012 TEST 40M 2 M 9 1 9.08 05/06/2012 TRAIN 41F 2 F 7 6 7.5 07/06/2012 TRAIN 42M 2 M 8 11 8.92 08/06/2012 TRAIN 43F 2 F 10 1 10.08 14/06/2012 TRAIN 44F 2 F 7 11 7.92 15/06/2012 TRAIN 45M 2 M 10 5 10.42 15/06/2012 TEST 46F 2 F 6 11 6.92 18/06/2012 TRAIN 47M 2 M 11 8 11.67 25/06/2012 TEST 48F 2 F 10 10 10.83 04/07/2012 TRAIN 49F 2 F 8 9 8.75 03/08/2012 TRAIN 50F 2 F 10 6 10.5 03/10/2012 TRAIN 51M 2 M 7 7 7.58 03/10/2012 TRAIN 52F 2 F 8 3 8.25 05/10/2012 TEST 53F 2 F 6 0 6.0 05/10/2012 TEST 54F 2 F 8 2 8.17 09/10/2012 TRAIN 55M 2 M 7 5 7.42 12/10/2012 TEST 56M 2 M 6 9 6.75 16/10/2012 TRAIN 57F 2 F 7 5 7.42 16/10/2012 DEV 58F 2 F 9 1 9.08 17/10/2012 DEV","title":"Speakers"},{"location":"data/uxtd/","text":"UXTD - Ultrax Typically Developing Children A dataset of ultrasound and audio recordings from typically developing children Speakers The UXTD dataset contains 58 speakers (31 female and 27 male), aged 5-12 years. For a list and additional details, see UXTD Speakers . Data Types Core data types Data type Description wav speech waveform ult raw ultrasound data param ultrasound parameters txt prompt text with date/time of utterance recording Additional data All labels are provided in Praat's TextGrid format. Data type Description transcriptions transcription for utterances of type X and X. slt-labels manual annotation from SLT, when available. See [2] for details speaker-labels speaker diarization identifying therapist (SLT) and child (CHILD) speech word-labels automatic word-level alignment phone-labels automatic phone-level alignment File IDs Individual recordings are indexed for each session according to their recording times. See the prompt text file for recording date/time. Each file ID also includes a prompt type identifier. See Data for details. Download Download links will be made available soon References [1] Eshky, A., Ribeiro, M. S., Cleland, J., Richmond, K., Roxburgh, Z., Scobbie, J., & Wrench, A. (2018) Ultrasuite: A repository of ultrasound and acoustic data from child speech therapy sessions . Proceedings of INTERSPEECH. Hyderabad, India. [2] Cleland, J., Scobbie, J., Naki, S., & Wrench, A. (2015). Helping children learn non-native articulations: the implications for ultrasound-based clinical intervention. Proceedings of the 18th International Congress of Phonetic Sciences : ICPhS 2015. ed. / The Scottish Consortium for ICPhS 2015. 1. ed. Scotland, 2015. p. 1-5 698.","title":"Ultrax Typically Developing"},{"location":"data/uxtd/#uxtd-ultrax-typically-developing-children","text":"","title":"UXTD - Ultrax Typically Developing Children"},{"location":"data/uxtd/#a-dataset-of-ultrasound-and-audio-recordings-from-typically-developing-children","text":"","title":"A dataset of ultrasound and audio recordings from typically developing children"},{"location":"data/uxtd/#speakers","text":"The UXTD dataset contains 58 speakers (31 female and 27 male), aged 5-12 years. For a list and additional details, see UXTD Speakers .","title":"Speakers"},{"location":"data/uxtd/#data-types","text":"Core data types Data type Description wav speech waveform ult raw ultrasound data param ultrasound parameters txt prompt text with date/time of utterance recording Additional data All labels are provided in Praat's TextGrid format. Data type Description transcriptions transcription for utterances of type X and X. slt-labels manual annotation from SLT, when available. See [2] for details speaker-labels speaker diarization identifying therapist (SLT) and child (CHILD) speech word-labels automatic word-level alignment phone-labels automatic phone-level alignment","title":"Data Types"},{"location":"data/uxtd/#file-ids","text":"Individual recordings are indexed for each session according to their recording times. See the prompt text file for recording date/time. Each file ID also includes a prompt type identifier. See Data for details.","title":"File IDs"},{"location":"data/uxtd/#download","text":"Download links will be made available soon","title":"Download"},{"location":"data/uxtd/#references","text":"[1] Eshky, A., Ribeiro, M. S., Cleland, J., Richmond, K., Roxburgh, Z., Scobbie, J., & Wrench, A. (2018) Ultrasuite: A repository of ultrasound and acoustic data from child speech therapy sessions . Proceedings of INTERSPEECH. Hyderabad, India. [2] Cleland, J., Scobbie, J., Naki, S., & Wrench, A. (2015). Helping children learn non-native articulations: the implications for ultrasound-based clinical intervention. Proceedings of the 18th International Congress of Phonetic Sciences : ICPhS 2015. ed. / The Scottish Consortium for ICPhS 2015. 1. ed. Scotland, 2015. p. 1-5 698.","title":"References"}]}